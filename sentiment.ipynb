{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# An\u00e1lise de Sentimentos\n", "\n", "Neste notebook, ser\u00e1 feita uma an\u00e1lise de sentimentos com base em textos retirados do Twitter, aplicando Processamento de Linguagem Natural (PLN) com uso de Machine Learning."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 1: Instalando as bibliotecas e recarregando o ambiente"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install -U pip setuptools wheel\n", "%pip install -U spacy\n", "%pip install spacytextblob\n", "!python -m spacy download en_core_web_sm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 2: Importando as bibliotecas para an\u00e1lise de sentimento"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import spacy\n", "from spacytextblob.spacytextblob import SpacyTextBlob"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 3: Definindo o modelo e a pipeline a serem utilizadas na an\u00e1lise"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nlp = spacy.load('en_core_web_sm')\n", "nlp.add_pipe('spacytextblob')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 4: Definindo o texto inicial a ser analisado para verifica\u00e7\u00e3o/valida\u00e7\u00e3o da biblioteca"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["user_input = 'This is a wonderful campsite. I loved the serenity and the birds chirping in the morning.'\n", "doc = nlp(user_input)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 5: Exibindo o resultado da primeira an\u00e1lise (um range entre -1 e 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_polarity = doc._.polarity\n", "sentiment = {\n", "    'score': input_polarity\n", "}\n", "print(sentiment)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 6: Definindo a lista de tweets a serem analisadas"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tweets=[\n", "    \"Bayer Leverkusen goalkeeper Bernd Leno will not be going to Napoli...\",\n", "    \"Gary Speed v Blackburn at St James in 2001/02 anyone?\",\n", "    \"@ChelseaFC Don't make him regret it and start him over Hoofiz\",\n", "    \"@LiverpoolFF @AnfieldEdition He's a liar, made up...\",\n", "    \"@theesk @Everton Didn't realise Kenwright is due to leave...\",\n", "    \"@hasanshahbaz19 @LFC My knowledge has decreased...\",\n", "    \"Report: Linked with #Everton and #Wolves, Italians set to sign...\",\n", "    \"Am seeing tweets that there\u2019s been a fall out @Everton...\",\n", "    \"@LFC Expect loads of excuses after tonight\u2019s game\",\n", "    \"@MartinDiamond17 I\u2019m just fine I have your fanbase angry...\",\n", "    \"What a weekend of football results!\",\n", "    \"@ChelseaFC For the first time in a long while, my heart was relaxed...\",\n", "    \"@ChelseaFC What a fantastic signing worth every single penny\",\n", "    \"Pogba scores, Pogba assists... #mufc\",\n", "    \"@WestHamUtd we need to keep @CH14_ and get @HirvingLozano70\",\n", "    \"@kevdev9 @Everton Shouldn\u2019t be happening!...\",\n", "    \"@brfootball @aguerosergiokun @ManCity What a genius...\",\n", "    \"@HMZ0709 Can we get a RT for our #lfc Mo Salah Pin Badge\"\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Passo 7: Analisando os tweets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for item in tweets:\n", "    doc = nlp(item)\n", "    input_polarity = doc._.polarity\n", "    sentiment = {\n", "        'tweet': item,\n", "        'score': input_polarity\n", "    }\n", "    print(sentiment)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 2}